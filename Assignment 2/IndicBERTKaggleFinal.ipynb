{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-13T12:21:01.892430Z",
     "iopub.status.busy": "2024-03-13T12:21:01.892096Z",
     "iopub.status.idle": "2024-03-13T12:22:30.712115Z",
     "shell.execute_reply": "2024-03-13T12:22:30.711018Z",
     "shell.execute_reply.started": "2024-03-13T12:21:01.892400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece\n",
    "!pip3 install seqeval\n",
    "!pip3 install transformers[torch]\n",
    "!pip3 install accelerate -U\n",
    "!pip3 install accelerate>=0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:42.986345Z",
     "iopub.status.busy": "2024-03-13T12:22:42.985604Z",
     "iopub.status.idle": "2024-03-13T12:22:43.648760Z",
     "shell.execute_reply": "2024-03-13T12:22:43.647533Z",
     "shell.execute_reply.started": "2024-03-13T12:22:42.986312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all the necessary classes and initialize the tokenizer and model.\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:50.533467Z",
     "iopub.status.busy": "2024-03-13T12:22:50.533099Z",
     "iopub.status.idle": "2024-03-13T12:22:50.541924Z",
     "shell.execute_reply": "2024-03-13T12:22:50.541064Z",
     "shell.execute_reply.started": "2024-03-13T12:22:50.533436Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions( sentence, tokenizer, model ):\n",
    "  # Let us first tokenize the sentence - split words into subwords\n",
    "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "  with torch.no_grad():\n",
    "    # we will send the tokenized sentence to the model to get predictions\n",
    "    logits = model(**tok_sentence).logits.argmax(-1)\n",
    "\n",
    "    # We will map the maximum predicted class id with the class label\n",
    "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "    predicted_labels = []\n",
    "\n",
    "    previous_token_id = 0\n",
    "    # we need to assign the named entity label to the head word and not the following sub-words\n",
    "    word_ids = tok_sentence.word_ids()\n",
    "    for word_index in range(len(word_ids)):\n",
    "        if word_ids[word_index] == None:\n",
    "            previous_token_id = word_ids[word_index]\n",
    "        elif word_ids[word_index] == previous_token_id:\n",
    "            previous_token_id = word_ids[word_index]\n",
    "        else:\n",
    "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
    "            previous_token_id = word_ids[word_index]\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:50.543799Z",
     "iopub.status.busy": "2024-03-13T12:22:50.543500Z",
     "iopub.status.idle": "2024-03-13T12:22:50.652127Z",
     "shell.execute_reply": "2024-03-13T12:22:50.651009Z",
     "shell.execute_reply.started": "2024-03-13T12:22:50.543767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "लगातार\tO\n",
      "हमलावर\tO\n",
      "हो\tO\n",
      "रहे\tO\n",
      "शिवपाल\tB-PER\n",
      "और\tO\n",
      "राजभर\tB-PER\n",
      "को\tO\n",
      "सपा\tB-ORG\n",
      "की\tO\n",
      "दो\tO\n",
      "टूक,\tO\n",
      "चिट्ठी\tO\n",
      "जारी\tO\n",
      "कर\tO\n",
      "कहा-\tO\n",
      "जहां\tO\n",
      "जाना\tO\n",
      "चाहें\tO\n",
      "जा\tO\n",
      "सकते\tO\n",
      "हैं\tO\n"
     ]
    }
   ],
   "source": [
    "# let us try with some example sentences here\n",
    "sentence = 'लगातार हमलावर हो रहे शिवपाल और राजभर को सपा की दो टूक, चिट्ठी जारी कर कहा- जहां जाना चाहें जा सकते हैं'\n",
    "\n",
    "predicted_labels = get_predictions(sentence=sentence,\n",
    "                                   tokenizer=tokenizer,\n",
    "                                   model=model\n",
    "                                   )\n",
    "\n",
    "for index in range(len(sentence.split(' '))):\n",
    "  print(sentence.split(' ')[index] + '\\t' + predicted_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naampadam Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:52.426300Z",
     "iopub.status.busy": "2024-03-13T12:22:52.425920Z",
     "iopub.status.idle": "2024-03-13T12:22:52.855890Z",
     "shell.execute_reply": "2024-03-13T12:22:52.854978Z",
     "shell.execute_reply.started": "2024-03-13T12:22:52.426267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf972bfc6efd49dabb45f83ef00c4034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's download the Naampadam (Indic NER) dataset\n",
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "\n",
    "lang='hi'\n",
    "\n",
    "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:53.859377Z",
     "iopub.status.busy": "2024-03-13T12:22:53.858548Z",
     "iopub.status.idle": "2024-03-13T12:22:53.864793Z",
     "shell.execute_reply": "2024-03-13T12:22:53.863751Z",
     "shell.execute_reply.started": "2024-03-13T12:22:53.859336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 985787\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 867\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 13460\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:56.501532Z",
     "iopub.status.busy": "2024-03-13T12:22:56.500899Z",
     "iopub.status.idle": "2024-03-13T12:22:56.508085Z",
     "shell.execute_reply": "2024-03-13T12:22:56.507044Z",
     "shell.execute_reply.started": "2024-03-13T12:22:56.501496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['tokens', 'ner_tags'],\n",
       " 'test': ['tokens', 'ner_tags'],\n",
       " 'validation': ['tokens', 'ner_tags']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:57.837167Z",
     "iopub.status.busy": "2024-03-13T12:22:57.836548Z",
     "iopub.status.idle": "2024-03-13T12:22:57.843651Z",
     "shell.execute_reply": "2024-03-13T12:22:57.842679Z",
     "shell.execute_reply.started": "2024-03-13T12:22:57.837129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कांग्रेस\t3\n",
      "के\t0\n",
      "दो\t0\n",
      "बागी\t0\n",
      "विधायकों\t0\n",
      "-\t0\n",
      "-\t0\n",
      "अल्पेश\t1\n",
      "ठाकोर\t2\n",
      "और\t0\n",
      "उनके\t0\n",
      "करीबी\t0\n",
      "सहयोगी\t0\n",
      "धवल\t1\n",
      "सिंह\t2\n",
      "झाला\t2\n",
      "ने\t0\n",
      "भाजपा\t3\n",
      "के\t0\n",
      "पक्ष\t0\n",
      "में\t0\n",
      "मतदान\t0\n",
      "किया\t0\n",
      "।\t0\n"
     ]
    }
   ],
   "source": [
    "# let's print an instance of dataset\n",
    "idx=20\n",
    "rec=raw_datasets['train'][idx]\n",
    "for w, t in zip(rec['tokens'],rec['ner_tags']):\n",
    "  print('{}\\t{}'.format(w,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:22:59.575564Z",
     "iopub.status.busy": "2024-03-13T12:22:59.574662Z",
     "iopub.status.idle": "2024-03-13T12:22:59.580950Z",
     "shell.execute_reply": "2024-03-13T12:22:59.579973Z",
     "shell.execute_reply.started": "2024-03-13T12:22:59.575531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokens', 'ner_tags']\n",
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "column_names = raw_datasets[\"train\"].column_names\n",
    "print(column_names)\n",
    "\n",
    "features = raw_datasets[\"train\"].features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:00.957285Z",
     "iopub.status.busy": "2024-03-13T12:23:00.956209Z",
     "iopub.status.idle": "2024-03-13T12:23:00.961868Z",
     "shell.execute_reply": "2024-03-13T12:23:00.960553Z",
     "shell.execute_reply.started": "2024-03-13T12:23:00.957242Z"
    }
   },
   "outputs": [],
   "source": [
    "text_column_name = \"tokens\"\n",
    "label_column_name = \"ner_tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:05.458234Z",
     "iopub.status.busy": "2024-03-13T12:23:05.457517Z",
     "iopub.status.idle": "2024-03-13T12:23:05.464749Z",
     "shell.execute_reply": "2024-03-13T12:23:05.463536Z",
     "shell.execute_reply.started": "2024-03-13T12:23:05.458197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n",
    "\n",
    "label_list = features[label_column_name].feature.names\n",
    "\n",
    "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
    "\n",
    "print(label_to_id)\n",
    "\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an IndicBERT Model with the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Pre-trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:09.619305Z",
     "iopub.status.busy": "2024-03-13T12:23:09.618942Z",
     "iopub.status.idle": "2024-03-13T12:23:13.564572Z",
     "shell.execute_reply": "2024-03-13T12:23:13.563585Z",
     "shell.execute_reply.started": "2024-03-13T12:23:09.619275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfece7dde904bfd906d53932cc98dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:13.567537Z",
     "iopub.status.busy": "2024-03-13T12:23:13.567161Z",
     "iopub.status.idle": "2024-03-13T12:23:13.894224Z",
     "shell.execute_reply": "2024-03-13T12:23:13.893086Z",
     "shell.execute_reply.started": "2024-03-13T12:23:13.567501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the next cell if you want to use a GPU. Make sure that the Colab runtime is set accordingly\n",
    "\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize all texts and align the labels with them**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:21.758292Z",
     "iopub.status.busy": "2024-03-13T12:23:21.757403Z",
     "iopub.status.idle": "2024-03-13T12:23:21.766723Z",
     "shell.execute_reply": "2024-03-13T12:23:21.765293Z",
     "shell.execute_reply.started": "2024-03-13T12:23:21.758247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "padding = \"max_length\"\n",
    "def tokenize_and_align_labels(examples):\n",
    "    # print(\"x : \", examples)\n",
    "    # print(\"y : \",examples[text_column_name])\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        # print('=====')\n",
    "        # print('{} {}'.format(i,label)) #ak\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:23.792320Z",
     "iopub.status.busy": "2024-03-13T12:23:23.791407Z",
     "iopub.status.idle": "2024-03-13T12:23:30.577141Z",
     "shell.execute_reply": "2024-03-13T12:23:30.575918Z",
     "shell.execute_reply.started": "2024-03-13T12:23:23.792279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac7dcb61a0a409bac3de2444cf6a696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset #0:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e801f73a1e6b4dd18e500d6980886b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset #1:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d8fe91babe425086aa8f11b443b2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset #3:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0db70d77e64c16a50d3405dfd57973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset #2:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].select(range(20000))\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:30.579651Z",
     "iopub.status.busy": "2024-03-13T12:23:30.579338Z",
     "iopub.status.idle": "2024-03-13T12:23:35.458273Z",
     "shell.execute_reply": "2024-03-13T12:23:35.457209Z",
     "shell.execute_reply.started": "2024-03-13T12:23:30.579621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c681d4210a449b9ff953ede9cdd871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #1:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d70b6937f6a4639b99f8760284cf597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #0:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e783788cf23497fa416612a3c52ecf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #2:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b197859553034f408f780b39bbe91c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #3:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "eval_dataset = eval_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on Validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Data Collator, Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:35.460509Z",
     "iopub.status.busy": "2024-03-13T12:23:35.460193Z",
     "iopub.status.idle": "2024-03-13T12:23:35.465286Z",
     "shell.execute_reply": "2024-03-13T12:23:35.464360Z",
     "shell.execute_reply.started": "2024-03-13T12:23:35.460479Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:48.065719Z",
     "iopub.status.busy": "2024-03-13T12:23:48.064555Z",
     "iopub.status.idle": "2024-03-13T12:23:48.386583Z",
     "shell.execute_reply": "2024-03-13T12:23:48.385612Z",
     "shell.execute_reply.started": "2024-03-13T12:23:48.065667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5917f2f3d66242b39c636f1bba79f754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    print(\"dfd \",type(p))\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Training Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:52.922707Z",
     "iopub.status.busy": "2024-03-13T12:23:52.921433Z",
     "iopub.status.idle": "2024-03-13T12:23:52.936669Z",
     "shell.execute_reply": "2024-03-13T12:23:52.935740Z",
     "shell.execute_reply.started": "2024-03-13T12:23:52.922643Z"
    }
   },
   "outputs": [],
   "source": [
    "# args=TrainingArguments(output_dir='output_dir',max_steps=5)\n",
    "args=TrainingArguments(\n",
    "    output_dir='output_dir',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:54.808141Z",
     "iopub.status.busy": "2024-03-13T12:23:54.807052Z",
     "iopub.status.idle": "2024-03-13T12:23:56.288585Z",
     "shell.execute_reply": "2024-03-13T12:23:56.287483Z",
     "shell.execute_reply.started": "2024-03-13T12:23:54.808093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize our Trainer\n",
    "# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
    "# args.metric_for_best_model = \"f1\"\n",
    "# args.load_best_model_at_end = True\n",
    "# args.evaluation_strategy = IntervalStrategy.STEPS\n",
    "# args.eval_steps = args.save_steps\n",
    "# args.greater_is_better = True\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[early_stopping_callback],\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:23:56.336657Z",
     "iopub.status.busy": "2024-03-13T12:23:56.335985Z",
     "iopub.status.idle": "2024-03-13T12:23:56.345999Z",
     "shell.execute_reply": "2024-03-13T12:23:56.344902Z",
     "shell.execute_reply.started": "2024-03-13T12:23:56.336627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=2,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=False,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=500,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=3e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=output_dir/runs/Mar13_12-23-52_7c0f412bb0cf,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=output_dir,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=16,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard', 'wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=output_dir,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=300,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args.num_train_epochs = 3\n",
    "trainer.args.evaluation_strategy = \"epoch\"\n",
    "trainer.args.eval_steps = 500\n",
    "trainer.args.learning_rate = 3e-5\n",
    "trainer.args.per_device_train_batch_size = 16\n",
    "trainer.args.weight_decay = 0.01\n",
    "trainer.args.gradient_accumulation_steps = 1\n",
    "trainer.args.warmup_steps = 300\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T12:24:00.553856Z",
     "iopub.status.busy": "2024-03-13T12:24:00.552978Z",
     "iopub.status.idle": "2024-03-13T13:21:16.183654Z",
     "shell.execute_reply": "2024-03-13T13:21:16.182425Z",
     "shell.execute_reply.started": "2024-03-13T12:24:00.553817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240313_122442-uemb5t8h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/anshulpurohit11/huggingface/runs/uemb5t8h' target=\"_blank\">honest-butterfly-10</a></strong> to <a href='https://wandb.ai/anshulpurohit11/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/anshulpurohit11/huggingface' target=\"_blank\">https://wandb.ai/anshulpurohit11/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/anshulpurohit11/huggingface/runs/uemb5t8h' target=\"_blank\">https://wandb.ai/anshulpurohit11/huggingface/runs/uemb5t8h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 55:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Number</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Number</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.340406</td>\n",
       "      <td>0.568740</td>\n",
       "      <td>0.680505</td>\n",
       "      <td>0.619623</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.524615</td>\n",
       "      <td>0.389843</td>\n",
       "      <td>0.447297</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.606827</td>\n",
       "      <td>0.635882</td>\n",
       "      <td>0.621015</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.572041</td>\n",
       "      <td>0.572022</td>\n",
       "      <td>0.572031</td>\n",
       "      <td>0.897575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311000</td>\n",
       "      <td>0.291150</td>\n",
       "      <td>0.700156</td>\n",
       "      <td>0.659845</td>\n",
       "      <td>0.679403</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.526807</td>\n",
       "      <td>0.508073</td>\n",
       "      <td>0.517270</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.703289</td>\n",
       "      <td>0.641465</td>\n",
       "      <td>0.670956</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.644206</td>\n",
       "      <td>0.604901</td>\n",
       "      <td>0.623935</td>\n",
       "      <td>0.911345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.284142</td>\n",
       "      <td>0.687506</td>\n",
       "      <td>0.690199</td>\n",
       "      <td>0.688850</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.538144</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>0.528773</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.698874</td>\n",
       "      <td>0.663891</td>\n",
       "      <td>0.680934</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.643883</td>\n",
       "      <td>0.626525</td>\n",
       "      <td>0.635085</td>\n",
       "      <td>0.912943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfd  <class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfd  <class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfd  <class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:32:49.708599Z",
     "iopub.status.busy": "2024-03-13T13:32:49.707781Z",
     "iopub.status.idle": "2024-03-13T13:32:50.078452Z",
     "shell.execute_reply": "2024-03-13T13:32:50.077110Z",
     "shell.execute_reply.started": "2024-03-13T13:32:49.708556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INDICBERTTokenizer/tokenizer_config.json',\n",
       " 'INDICBERTTokenizer/special_tokens_map.json',\n",
       " 'INDICBERTTokenizer/spiece.model',\n",
       " 'INDICBERTTokenizer/added_tokens.json',\n",
       " 'INDICBERTTokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"INDICBERT\")\n",
    "tokenizer.save_pretrained(\"INDICBERTTokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:32:52.233196Z",
     "iopub.status.busy": "2024-03-13T13:32:52.232778Z",
     "iopub.status.idle": "2024-03-13T13:37:05.288010Z",
     "shell.execute_reply": "2024-03-13T13:37:05.286921Z",
     "shell.execute_reply.started": "2024-03-13T13:32:52.233164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='842' max='842' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [842/842 03:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfd  <class 'transformers.trainer_utils.EvalPrediction'>\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_LOC_f1             =     0.6888\n",
      "  eval_LOC_number         =      10213\n",
      "  eval_LOC_precision      =     0.6875\n",
      "  eval_LOC_recall         =     0.6902\n",
      "  eval_ORG_f1             =     0.5288\n",
      "  eval_ORG_number         =       9786\n",
      "  eval_ORG_precision      =     0.5381\n",
      "  eval_ORG_recall         =     0.5197\n",
      "  eval_PER_f1             =     0.6809\n",
      "  eval_PER_number         =      10568\n",
      "  eval_PER_precision      =     0.6989\n",
      "  eval_PER_recall         =     0.6639\n",
      "  eval_loss               =     0.2841\n",
      "  eval_overall_accuracy   =     0.9129\n",
      "  eval_overall_f1         =     0.6351\n",
      "  eval_overall_precision  =     0.6439\n",
      "  eval_overall_recall     =     0.6265\n",
      "  eval_runtime            = 0:04:13.01\n",
      "  eval_samples_per_second =     53.197\n",
      "  eval_steps_per_second   =      3.328\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:37:05.289976Z",
     "iopub.status.busy": "2024-03-13T13:37:05.289655Z",
     "iopub.status.idle": "2024-03-13T13:37:05.303589Z",
     "shell.execute_reply": "2024-03-13T13:37:05.302442Z",
     "shell.execute_reply.started": "2024-03-13T13:37:05.289948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[early_stopping_callback],\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T13:37:05.305458Z",
     "iopub.status.busy": "2024-03-13T13:37:05.305082Z",
     "iopub.status.idle": "2024-03-13T13:43:19.307714Z",
     "shell.execute_reply": "2024-03-13T13:43:19.306378Z",
     "shell.execute_reply.started": "2024-03-13T13:37:05.305421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 05:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfd  <class 'transformers.trainer_utils.EvalPrediction'>\n",
      "***** train metrics *****\n",
      "  eval_LOC_f1             =     0.7352\n",
      "  eval_LOC_number         =      14841\n",
      "  eval_LOC_precision      =     0.7335\n",
      "  eval_LOC_recall         =     0.7369\n",
      "  eval_ORG_f1             =     0.5876\n",
      "  eval_ORG_number         =      14082\n",
      "  eval_ORG_precision      =     0.6003\n",
      "  eval_ORG_recall         =     0.5754\n",
      "  eval_PER_f1             =     0.7522\n",
      "  eval_PER_number         =      15614\n",
      "  eval_PER_precision      =     0.7715\n",
      "  eval_PER_recall         =     0.7339\n",
      "  eval_loss               =      0.232\n",
      "  eval_overall_accuracy   =     0.9313\n",
      "  eval_overall_f1         =     0.6947\n",
      "  eval_overall_precision  =      0.705\n",
      "  eval_overall_recall     =     0.6848\n",
      "  eval_runtime            = 0:06:13.94\n",
      "  eval_samples_per_second =     53.484\n",
      "  eval_steps_per_second   =      3.343\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"train\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
