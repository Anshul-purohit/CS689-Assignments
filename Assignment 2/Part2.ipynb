{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea84101b-2f21-4b4a-a091-af2367952534",
   "metadata": {},
   "source": [
    "# indicBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3812a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64a1961-c908-4a1e-b881-b837ec720862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"INDICBERTTokenizer/working/tokenizer_indicBERT\")\n",
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"INDICBERT/working/my_indicBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76267445-e8f0-450b-9dd9-6e66259ad772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download the Naampadam (Indic NER) dataset\n",
    "\n",
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "\n",
    "lang='hi'\n",
    "\n",
    "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8933010e-8144-48af-a970-a40475f52152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "padding = \"max_length\"\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    # print(tokenized_inputs)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        # print('=====')\n",
    "        # print('{} {}'.format(i,label)) #ak\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    # print(tokenized_inputs)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ac689d-77a6-4ecf-9f5b-5d7c9588e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_test  = raw_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0791b05c-305c-4575-aa93-d02c683b3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abee09f1-9239-432d-a2f4-44c3af6f1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset_test\n",
    "\n",
    "test_data=[]\n",
    "\n",
    "for i in sample['tokens']:\n",
    "    sentence = ' '.join(i)\n",
    "    test_data.append(sentence)\n",
    "\n",
    "ground_truth = []\n",
    "\n",
    "for i in sample['ner_tags']:\n",
    "    output_list = [label_mapping[num] for num in i]\n",
    "    ground_truth.append(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56581683-5983-4c1f-a6f7-3fd2f4d48665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_fine_tuned(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model_fine_tuned.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        l = min (len(sentence.split(' ')) , len(predicted_labels) )\n",
    "        for index in range(l):\n",
    "            ner_output.append(\n",
    "                (sentence.split(' ')[index], predicted_labels[index]))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a70e85-cbf0-4188-969d-7d48c62fd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "labeled_output = []\n",
    "output=[]\n",
    "for i in test_data:\n",
    "    l = get_ner(i)\n",
    "    labeled_output.append(l)\n",
    "    temp=[]\n",
    "    for j in l:\n",
    "        temp.append(j[1])\n",
    "    output.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3364db70-cad5-4439-8d43-fdfe3c69cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "for i in output:\n",
    "    tags_string = ' '.join(i)\n",
    "    temp = tags_string.strip().split()\n",
    "    b.append(temp)\n",
    "\n",
    "g = []\n",
    "labels_list=[]\n",
    "\n",
    "for i in range(len(ground_truth)):\n",
    "    tags_string = ' '.join(ground_truth[i])\n",
    "    labels_list = tags_string.strip().split()\n",
    "    g.append(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b721c31-a78a-4aa0-83e3-21bafa94c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(867):\n",
    "    x = len(b[i])\n",
    "    y = len(g[i])\n",
    "    while(x<y):\n",
    "        b[i].append('NA')\n",
    "        x = len(b[i])\n",
    "        y = len(g[i])\n",
    "        \n",
    "    while(x>y):\n",
    "        b[i].pop()\n",
    "        x = len(b[i])\n",
    "        y = len(g[i])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488eeeab-7bc3-4851-9e02-f51d2d758361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.98      0.98     16513\n",
      "       I-ORG       0.81      0.77      0.79       512\n",
      "       B-LOC       0.82      0.81      0.82       613\n",
      "       I-PER       0.91      0.91      0.91       747\n",
      "       B-PER       0.85      0.89      0.87       788\n",
      "       I-LOC       0.80      0.59      0.68       199\n",
      "       B-ORG       0.79      0.81      0.80       521\n",
      "\n",
      "    accuracy                           0.95     19893\n",
      "   macro avg       0.85      0.82      0.83     19893\n",
      "weighted avg       0.95      0.95      0.95     19893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ground_truth_flat_bert = [label for sublist in g for label in sublist]\n",
    "predicted_labels_flat_bert = [label for sublist in b for label in sublist]\n",
    "\n",
    "print(classification_report(ground_truth_flat_bert, predicted_labels_flat_bert, labels=[label for label in set(ground_truth_flat_bert) if label != 'NA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7199694d-1663-4a39-a089-5bbf0466732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.6490502408696407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubyp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores_bert = f1_score(ground_truth_flat_bert, predicted_labels_flat_bert, labels=['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'], average=None)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1_bert = sum(f1_scores_bert) / len(f1_scores_bert)\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958235a-75a4-4d3c-859b-4f15f8baef7f",
   "metadata": {},
   "source": [
    "# indic_NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d75ca30c-a751-43a2-93ab-810e1ea33e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"INDICNERTokenizer/working/tokenizer_indicNER\")\n",
    "model_fine_tuned_ner = AutoModelForTokenClassification.from_pretrained(\"INDICNER/working/my_indicNER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "453014d6-6815-432e-87f4-ad53cd715416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer_ner(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_fine_tuned_ner(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model_fine_tuned_ner.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        l = min (len(sentence.split(' ')) , len(predicted_labels) )\n",
    "        for index in range(l):\n",
    "            ner_output.append(\n",
    "                (sentence.split(' ')[index], predicted_labels[index]))\n",
    "        return ner_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b670188c-13f0-4c15-96df-413661c84b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str = \"दरअसल , जनवरी से चीन और नेपाल के सीमावर्ती क्षेत्रों को संचार सुविधा के लिए अब बैलून नेटवर्क सिस्टम की शुरूआत की जा रही है, जिसके साथ ही उत्तराखंड बैलून से नेटवर्क सुविधा देने वाला पहला राज्य बनेगा।  \"\n",
    "labeled_output_ner = []\n",
    "output_ner=[]\n",
    "for i in test_data:\n",
    "    l = get_ner(i)\n",
    "    labeled_output_ner.append(l)\n",
    "    temp=[]\n",
    "    for j in l:\n",
    "        temp.append(j[1])\n",
    "    output_ner.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43404e0f-1b53-4d7b-abf5-2cc1ba7dd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[]\n",
    "for i in output_ner:\n",
    "    tags = ' '.join(i)\n",
    "    temp = tags.strip().split()\n",
    "    n.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d3558f4-221c-4217-b2d5-0078adea12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(867):\n",
    "    x = len(n[i])\n",
    "    y = len(g[i])\n",
    "    while(x<y):\n",
    "        b[i].append('NA')\n",
    "        x = len(n[i])\n",
    "        y = len(g[i])\n",
    "        \n",
    "    while(x>y):\n",
    "        b[i].pop()\n",
    "        x = len(n[i])\n",
    "        y = len(g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f118097-99d2-4f86-bf90-95dcbb641479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.97      0.98     16513\n",
      "       I-ORG       0.68      0.78      0.73       512\n",
      "       B-LOC       0.85      0.87      0.86       613\n",
      "       I-PER       0.90      0.94      0.92       747\n",
      "       B-PER       0.88      0.92      0.90       788\n",
      "       I-LOC       0.83      0.66      0.74       199\n",
      "       B-ORG       0.74      0.83      0.79       521\n",
      "\n",
      "    accuracy                           0.95     19893\n",
      "   macro avg       0.84      0.85      0.84     19893\n",
      "weighted avg       0.96      0.95      0.95     19893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ground_truth_flat_ner = [label for sublist in g for label in sublist]\n",
    "predicted_labels_flat_ner = [label for sublist in n for label in sublist]\n",
    "\n",
    "print(classification_report(ground_truth_flat_ner, predicted_labels_flat_ner, labels=[label for label in set(ground_truth_flat_ner) if label != 'NA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "483d0222-fece-4a58-85cb-cbff11a82d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.6563827168901009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubyp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores_ner = f1_score(ground_truth_flat_ner, predicted_labels_flat_ner, labels=['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'], average=None)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1_ner = sum(f1_scores_ner) / len(f1_scores_ner)\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332719a-57f9-4ff4-b658-2864512d6153",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
