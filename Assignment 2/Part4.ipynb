{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763842eb",
   "metadata": {},
   "source": [
    "# CHATGPT vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15f8ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('manual.txt', 'r') as file:\n",
    "    # Read the file line by line\n",
    "    text = file.readlines()\n",
    "    \n",
    "    \n",
    "# print(text)\n",
    "ground_truth=[]\n",
    "\n",
    "for str in text:\n",
    "    string = str.split()\n",
    "    ground_truth.append(string)\n",
    "    \n",
    "    \n",
    "# print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b697f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode\n",
    "with open('gpt.txt', 'r') as file:\n",
    "    # Read the file line by line\n",
    "    text = file.readlines()\n",
    "    \n",
    "    \n",
    "# print(text)\n",
    "chatgpt=[]\n",
    "\n",
    "for str in text:\n",
    "    string = str.split()\n",
    "    chatgpt.append(string)\n",
    "    \n",
    "# print((chatgpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b0f35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(25):\n",
    "#     print(i , \" g : \", len(ground_truth[i]) , \" c : \" , len(chatgpt[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "883093d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       1.00      0.80      0.89         5\n",
      "      B-MISC       0.00      0.00      0.00        14\n",
      "       B-ORG       0.00      0.00      0.00         5\n",
      "       B-PER       1.00      0.64      0.78        11\n",
      "      I-MISC       0.00      0.00      0.00         7\n",
      "       I-ORG       0.00      0.00      0.00         2\n",
      "       I-PER       1.00      1.00      1.00         7\n",
      "           O       0.95      1.00      0.97       634\n",
      "\n",
      "    accuracy                           0.95       685\n",
      "   macro avg       0.49      0.43      0.46       685\n",
      "weighted avg       0.91      0.95      0.93       685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ground_truth_flat = [label for sublist in ground_truth for label in sublist]\n",
    "predicted_labels_flat = [label for sublist in chatgpt for label in sublist]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(ground_truth_flat, predicted_labels_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a053625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.40458906254448146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores_gpt = f1_score(ground_truth_flat, predicted_labels_flat, labels=['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'], average=None)\n",
    "\n",
    "# Calculate macro F1 score\n",
    "macro_f1_gpt = sum(f1_scores_gpt) / len(f1_scores_gpt)\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92daf112",
   "metadata": {},
   "source": [
    "# IndicBERT vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27768f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8254d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44758c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"INDICBERTTokenizer/working/tokenizer_indicBERT\")\n",
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"INDICBERT/working/my_indicBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3476c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('25sentences.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the contents of the file\n",
    "    Inp1 = file.readlines()\n",
    "\n",
    "corpus=[]\n",
    "\n",
    "i=0\n",
    "while (i<(len(Inp1)-1)):\n",
    "    x = Inp1[i]\n",
    "    x=x[2:-1]\n",
    "    corpus.append(x)\n",
    "    i+=3\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcfcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_fine_tuned(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model_fine_tuned.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        l = min (len(sentence.split(' ')) , len(predicted_labels) )\n",
    "        for index in range(l):\n",
    "            ner_output.append(\n",
    "                (sentence.split(' ')[index], predicted_labels[index]))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28a924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str = \"दरअसल , जनवरी से चीन और नेपाल के सीमावर्ती क्षेत्रों को संचार सुविधा के लिए अब बैलून नेटवर्क सिस्टम की शुरूआत की जा रही है, जिसके साथ ही उत्तराखंड बैलून से नेटवर्क सुविधा देने वाला पहला राज्य बनेगा।  \"\n",
    "labeled_output = []\n",
    "output=[]\n",
    "for i in corpus:\n",
    "    l = get_ner(i)\n",
    "    labeled_output.append(l)\n",
    "    temp=[]\n",
    "    for j in l:\n",
    "        temp.append(j[1])\n",
    "    output.append(temp)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c5729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "for i in output:\n",
    "    x = ' '.join(i)\n",
    "    temp = x.strip().split()\n",
    "    b.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accee565",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ground_truth\n",
    "for i in range(25):\n",
    "    x = len(b[i])\n",
    "    y = len(g[i])\n",
    "    while(x<y):\n",
    "        b[i].append('NA')\n",
    "        x = len(b[i])\n",
    "        y = len(g[i])\n",
    "        \n",
    "    while(x>y):\n",
    "        b[i].pop()\n",
    "        x = len(b[i])\n",
    "        y = len(g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d764f6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-PER       0.50      0.43      0.46         7\n",
      "       B-LOC       0.50      0.40      0.44         5\n",
      "       I-ORG       0.25      0.50      0.33         2\n",
      "       B-ORG       0.33      0.40      0.36         5\n",
      "      I-MISC       0.00      0.00      0.00         7\n",
      "       B-PER       0.44      0.36      0.40        11\n",
      "           O       0.95      0.94      0.94       634\n",
      "      B-MISC       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.92      0.89      0.91       685\n",
      "   macro avg       0.37      0.38      0.37       685\n",
      "weighted avg       0.90      0.89      0.89       685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ground_truth_flat_bert = [label for sublist in g for label in sublist]\n",
    "predicted_labels_flat_bert = [label for sublist in b for label in sublist]\n",
    "\n",
    "print(classification_report(ground_truth_flat_bert, predicted_labels_flat_bert, labels=[label for label in set(ground_truth_flat_bert) if label != 'NA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bcfb07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.32741524918880427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores_bert = f1_score(ground_truth_flat_bert, predicted_labels_flat_bert, labels=['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'], average=None)\n",
    "\n",
    "macro_f1_bert = sum(f1_scores_bert) / len(f1_scores_bert)\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6d320",
   "metadata": {},
   "source": [
    "# IndicNER vs Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b8aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_ner = AutoTokenizer.from_pretrained(\"INDICNERTokenizer/working/tokenizer_indicNER\")\n",
    "model_fine_tuned_ner = AutoModelForTokenClassification.from_pretrained(\"INDICNER/working/my_indicNER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6adf33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer_ner(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_fine_tuned_ner(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model_fine_tuned_ner.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        l = min (len(sentence.split(' ')) , len(predicted_labels) )\n",
    "        for index in range(l):\n",
    "            ner_output.append(\n",
    "                (sentence.split(' ')[index], predicted_labels[index]))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d733c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_output_ner = []\n",
    "output_ner=[]\n",
    "for i in corpus:\n",
    "    l = get_ner(i)\n",
    "    labeled_output_ner.append(l)\n",
    "    temp=[]\n",
    "    for j in l:\n",
    "        temp.append(j[1])\n",
    "    output_ner.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a5093b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[]\n",
    "for i in output_ner:\n",
    "    x = ' '.join(i)\n",
    "    temp = x.strip().split()\n",
    "    n.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb94ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    x = len(n[i])\n",
    "    y = len(g[i])\n",
    "    while(x<y):\n",
    "        n[i].append('NA')\n",
    "        x = len(n[i])\n",
    "        y = len(g[i])\n",
    "        \n",
    "    while(x>y):\n",
    "        n[i].pop()\n",
    "        x = len(n[i])\n",
    "        y = len(g[i])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2804f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-PER       0.50      0.43      0.46         7\n",
      "       B-LOC       0.25      0.20      0.22         5\n",
      "       I-ORG       0.14      0.50      0.22         2\n",
      "       B-ORG       0.25      0.40      0.31         5\n",
      "      I-MISC       0.00      0.00      0.00         7\n",
      "       B-PER       0.38      0.45      0.42        11\n",
      "           O       0.96      0.95      0.95       634\n",
      "      B-MISC       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.92      0.89      0.91       685\n",
      "   macro avg       0.31      0.37      0.32       685\n",
      "weighted avg       0.90      0.89      0.90       685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ground_truth_flat_ner = [label for sublist in g for label in sublist ]\n",
    "predicted_labels_flat_ner = [label for sublist in n for label in sublist]\n",
    "\n",
    "\n",
    "print(classification_report(ground_truth_flat_ner, predicted_labels_flat_ner, labels=[label for label in set(ground_truth_flat_ner) if label != 'NA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83463f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.2868015014079462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulpurohit/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores_ner = f1_score(ground_truth_flat_ner, predicted_labels_flat_ner, labels=['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'], average=None)\n",
    "\n",
    "macro_f1_ner = sum(f1_scores_ner) / len(f1_scores_ner)\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb090b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
