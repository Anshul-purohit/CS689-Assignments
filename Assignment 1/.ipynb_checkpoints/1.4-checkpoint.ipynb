{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d92f3f",
   "metadata": {},
   "source": [
    "# Question : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28b3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_array(arr, target):\n",
    "    for element in arr:\n",
    "        if element == target:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "halant = '\\u094D'\n",
    "a = 'अ'\n",
    "\n",
    "vowels = ['अ', 'आ', 'इ', 'ई', 'उ', 'ए', 'ऐ', 'ओ', 'औ']\n",
    "\n",
    "consonants = ['क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह']\n",
    "\n",
    "matra_to_vowels = {\n",
    "    'ा': 'आ',   # a matra\n",
    "    'ि': 'इ',   # i matra\n",
    "    'ी': 'ई',   # ii matra\n",
    "    'ु': 'उ',   # u matra\n",
    "    'ू': 'ऊ',   # uu matra\n",
    "    'ृ': 'ऋ',   # ri matra\n",
    "    'ॄ': 'ऋ',   # rii matra\n",
    "    'ॅ': 'ऌ',   # vocalic l matra\n",
    "    'ॆ': 'ए',   # e matra\n",
    "    'े': 'ए',   # ee matra\n",
    "    'ै': 'ऐ',   # ai matra\n",
    "    'ो': 'ओ',   # o matra\n",
    "    'ौ': 'औ',   # au matra\n",
    "    'ं': 'अं',   # chandrabindu matra \n",
    "    'ः': 'अः',   # anunasika matra\n",
    "}\n",
    "\n",
    "vowels_to_matras = {\n",
    "    'अ' : '',\n",
    "    'आ': '\\u093E',  # आ\n",
    "    'इ': '\\u093F',  # इ\n",
    "    'ई': '\\u0940',  # ई\n",
    "    'उ': '\\u0941',  # उ\n",
    "    'ऊ': '\\u0942',  # ऊ\n",
    "    'ए': '\\u0947',  # ए\n",
    "    'ऐ': '\\u0948',  # ऐ\n",
    "    'ओ': '\\u094B',  # ओ\n",
    "    'औ': '\\u094C',  # औ\n",
    "    'अं':  'ं',\n",
    "    'अः': 'ः'\n",
    "}\n",
    "\n",
    "# with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "#     # Read the entire contents of the file\n",
    "#     str = file.read()\n",
    "\n",
    "\n",
    "anusvara = 'ं'\n",
    "anunasik = 'ँ'\n",
    "ri = 'ऋ'\n",
    "\n",
    "\n",
    "# for i in str:\n",
    "#     print(i)\n",
    "\n",
    "def something(str):\n",
    "    ans=[]\n",
    "    for i in str:\n",
    "        if(i>='0' and i<='9'):\n",
    "            ans.append(i)\n",
    "            continue\n",
    "        if(i==\" \"):\n",
    "            ans.append(\" \")\n",
    "            continue\n",
    "        if(i==anusvara):\n",
    "            ans.append('अं')\n",
    "            continue\n",
    "\n",
    "        if(i==anunasik):\n",
    "            if(len(ans)>0):\n",
    "                temp = ans[len(ans)-1]\n",
    "                ans = ans[:-1]\n",
    "                ans.append(temp+i)\n",
    "                continue\n",
    "\n",
    "        if(i==halant):\n",
    "            ans = ans[:-1]\n",
    "\n",
    "        if(i==ri):\n",
    "            ans.append(ri)\n",
    "            continue\n",
    "\n",
    "        find = search_array(vowels,i)\n",
    "        if(find):\n",
    "            ans.append(i)\n",
    "            continue\n",
    "\n",
    "        find = search_array(consonants,i)\n",
    "        if(find):\n",
    "            ans.append(i+halant)\n",
    "            ans.append(a)\n",
    "\n",
    "        for key in matra_to_vowels:\n",
    "            if(i==key):\n",
    "                ans = ans[:-1]\n",
    "                ans.append(matra_to_vowels[key])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4652ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable(s):\n",
    "    i = 0\n",
    "    res = []\n",
    "    str = \"\"\n",
    "    while i<len(s):\n",
    "        if s[i] in vowels:\n",
    "            str = str + s[i]\n",
    "            if(i+1<len(s) and s[i+1]=='अं'):\n",
    "                str = str + s[i+1]\n",
    "                i = i + 1\n",
    "            res.append(str)\n",
    "            str = \"\"\n",
    "        else:\n",
    "            str = str + s[i]\n",
    "        i = i + 1\n",
    "    if(len(str)>0):\n",
    "        res.append(str)\n",
    "\n",
    "    ans = []\n",
    "#     print(res)\n",
    "    temp = \"\"\n",
    "    for i in res:\n",
    "        for j in i:\n",
    "            if j in consonants:\n",
    "                for k in consonants:\n",
    "                    if(k==j):\n",
    "                        temp = temp + k\n",
    "                        break\n",
    "                continue\n",
    "            if (j==halant):\n",
    "                temp = temp + j\n",
    "                continue\n",
    "            if j in vowels:\n",
    "                if(len(temp)==0):\n",
    "                    temp = temp + j\n",
    "                    continue\n",
    "                xx = temp[len(temp)-1]\n",
    "                if(xx==halant):\n",
    "                    temp = temp[:-1]\n",
    "                    temp = temp + vowels_to_matras[j]\n",
    "                else:\n",
    "                    temp = temp + vowels_to_matras[j]\n",
    "            else:\n",
    "                if(len(temp)>0):\n",
    "                    temp = temp + j\n",
    "        if(temp):\n",
    "            ans.append(temp)\n",
    "        temp = \"\"\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed5abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Define Hindi punctuation marks\n",
    "    hindi_punctuation = '।‘’“”!\"\\'(),-./;?[]_{}|'\n",
    "\n",
    "    # Create a translation table\n",
    "    translator = str.maketrans('', '', hindi_punctuation)\n",
    "\n",
    "    # Remove punctuation using translate method\n",
    "    text_without_punct = text.translate(translator)\n",
    "\n",
    "    # Remove any additional whitespace\n",
    "    text_without_punct = re.sub(r'\\s+', ' ', text_without_punct)\n",
    "\n",
    "    return text_without_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78afbe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=hi_100.txt --model_prefix=m_unigram --vocab_size=2000 --model_type=unigram\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: m_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=18991333\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 395429 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 324920 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=156332 obj=10.8621 num_tokens=702942 num_tokens/piece=4.49647\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=134610 obj=8.92531 num_tokens=703641 num_tokens/piece=5.22726\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=100903 obj=8.88768 num_tokens=727710 num_tokens/piece=7.21198\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=100760 obj=8.87633 num_tokens=727853 num_tokens/piece=7.22363\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=75563 obj=8.91628 num_tokens=768262 num_tokens/piece=10.1672\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=75557 obj=8.90731 num_tokens=768256 num_tokens/piece=10.1679\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=56667 obj=8.96362 num_tokens=813830 num_tokens/piece=14.3616\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=56667 obj=8.95147 num_tokens=813800 num_tokens/piece=14.3611\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=42500 obj=9.0328 num_tokens=863216 num_tokens/piece=20.311\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=42500 obj=9.0174 num_tokens=863193 num_tokens/piece=20.3104\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=31875 obj=9.12149 num_tokens=915167 num_tokens/piece=28.7111\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=31875 obj=9.10142 num_tokens=915173 num_tokens/piece=28.7113\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=23906 obj=9.23421 num_tokens=969065 num_tokens/piece=40.5365\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=23906 obj=9.21287 num_tokens=969074 num_tokens/piece=40.5369\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=17929 obj=9.37773 num_tokens=1024155 num_tokens/piece=57.1228\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=17929 obj=9.34571 num_tokens=1024169 num_tokens/piece=57.1236\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=13446 obj=9.55358 num_tokens=1079886 num_tokens/piece=80.3128\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13446 obj=9.51426 num_tokens=1079931 num_tokens/piece=80.3162\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10084 obj=9.75948 num_tokens=1136993 num_tokens/piece=112.752\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10084 obj=9.7122 num_tokens=1137021 num_tokens/piece=112.755\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=7563 obj=9.9979 num_tokens=1195057 num_tokens/piece=158.014\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=7563 obj=9.94147 num_tokens=1195156 num_tokens/piece=158.027\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5672 obj=10.269 num_tokens=1256218 num_tokens/piece=221.477\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5672 obj=10.2032 num_tokens=1256276 num_tokens/piece=221.487\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4254 obj=10.57 num_tokens=1322515 num_tokens/piece=310.887\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4254 obj=10.4928 num_tokens=1322548 num_tokens/piece=310.895\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3190 obj=10.9027 num_tokens=1393553 num_tokens/piece=436.85\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3190 obj=10.8123 num_tokens=1393577 num_tokens/piece=436.858\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2392 obj=11.271 num_tokens=1471177 num_tokens/piece=615.041\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2392 obj=11.1744 num_tokens=1471222 num_tokens/piece=615.059\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2200 obj=11.3072 num_tokens=1492220 num_tokens/piece=678.282\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2200 obj=11.2792 num_tokens=1492210 num_tokens/piece=678.277\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: m_unigram.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: m_unigram.vocab\n"
     ]
    }
   ],
   "source": [
    "# Unigram\n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train('--input=hi_100.txt --model_prefix=m_unigram --vocab_size=2000 --model_type=unigram') \n",
    "sp_unigram = spm.SentencePieceProcessor() \n",
    "sp_unigram.load('m_unigram.model') \n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "\n",
    "# text = \"यह एक मिसाल है! इसमें: कोई विचार नहीं। क्या आप इसे समझ सकते हैं?\"\n",
    "    \n",
    "text = remove_punctuation(text)\n",
    "    \n",
    "t = sp_unigram.encode_as_pieces(text) \n",
    "ans = []\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='▁'):\n",
    "            continue\n",
    "        temp = temp + x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "# print(t)\n",
    "# print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b39072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  334547\n",
      "में  :  240312\n",
      "है  :  215702\n",
      "की  :  207142\n",
      "न  :  182864\n",
      "ी  :  171966\n",
      "ने  :  171658\n",
      "ल  :  164178\n",
      "को  :  161501\n",
      "र  :  161031\n",
      "से  :  158832\n",
      "का  :  157596\n",
      "क  :  147315\n",
      "म  :  131347\n",
      "स  :  124899\n",
      "ा  :  116112\n",
      "और  :  115529\n",
      "त  :  111537\n",
      "ों  :  109496\n",
      "पर  :  107528\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "f = sorted_freq[:20]\n",
    "for i,j in f:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36d4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  43579\n",
      "हैकि  :  25550\n",
      "ोंके  :  19382\n",
      "केसाथ  :  18442\n",
      "ोंमें  :  17840\n",
      "कहाकि  :  16115\n",
      "ोंको  :  14934\n",
      "केबाद  :  14491\n",
      "ोंकी  :  12679\n",
      "नेकहा  :  12216\n",
      "नेके  :  12169\n",
      "रहाहै  :  12021\n",
      "हैऔर  :  11321\n",
      "गयाहै  :  11061\n",
      "ताहै  :  10773\n",
      "रहेहैं  :  10177\n",
      "करनेके  :  8851\n",
      "रहीहै  :  8753\n",
      "ोंका  :  7886\n",
      "ोंसे  :  7860\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "f = sorted_freq[:20]\n",
    "for i,j in f:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7e821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7803a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397746da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=hi_100.txt --model_prefix=m_bpe --vocab_size=1000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: m_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1364729 min_freq=1990\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220725 size=20 all=7449 active=2256 piece=▁ल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117261 size=40 all=8844 active=3651 piece=िक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74160 size=60 all=10391 active=5198 piece=▁थ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58450 size=80 all=12553 active=7360 piece=त्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43528 size=100 all=14682 active=9489 piece=▁सं\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43241 min_freq=4149\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35408 size=120 all=16900 active=3171 piece=▁किया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28955 size=140 all=18442 active=4713 piece=न्ह\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24411 size=160 all=20405 active=6676 piece=▁राज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21882 size=180 all=22297 active=8568 piece=▁सर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19406 size=200 all=24144 active=10415 piece=▁चु\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19305 min_freq=2919\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17837 size=220 all=26375 active=3387 piece=गर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16215 size=240 all=27984 active=4996 piece=▁जी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14802 size=260 all=29833 active=6845 piece=रो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13436 size=280 all=31773 active=8785 piece=▁उप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12360 size=300 all=32981 active=9993 piece=▁पुलिस\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12356 min_freq=1941\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11890 size=320 all=34340 active=2990 piece=▁इसके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10951 size=340 all=35982 active=4632 piece=चार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10320 size=360 all=37937 active=6587 piece=▁द्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9811 size=380 all=39130 active=7780 piece=▁परि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9445 size=400 all=41055 active=9705 piece=्यों\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9415 min_freq=1429\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8960 size=420 all=42288 active=3222 piece=▁आय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8386 size=440 all=43529 active=4463 piece=▁दौर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8077 size=460 all=45064 active=5998 piece=▁चल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7730 size=480 all=46422 active=7356 piece=▁सकता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7442 size=500 all=47949 active=8883 piece=▁चुनाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7424 min_freq=1125\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7087 size=520 all=49692 active=4134 piece=▁भारतीय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6786 size=540 all=51326 active=5768 piece=▁अव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6635 size=560 all=52202 active=6644 piece=पर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6283 size=580 all=53798 active=8240 piece=▁क्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5999 size=600 all=55396 active=9838 piece=भाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5982 min_freq=904\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5774 size=620 all=56792 active=4071 piece=▁बो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5563 size=640 all=58473 active=5752 piece=योग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5284 size=660 all=59469 active=6748 piece=▁इससे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5123 size=680 all=60536 active=7815 piece=▁कुमार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4968 size=700 all=62054 active=9333 piece=ुक\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4952 min_freq=761\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4780 size=720 all=63542 active=4436 piece=वल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4563 size=740 all=64700 active=5594 piece=▁इस्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4433 size=760 all=65843 active=6737 piece=▁आम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4313 size=780 all=66568 active=7462 piece=▁आने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4158 size=800 all=67465 active=8359 piece=▁बंद\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4156 min_freq=659\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4025 size=820 all=68540 active=4417 piece=डे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3923 size=840 all=69446 active=5323 piece=▁इसमें\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: m_bpe.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: m_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "# BPE\n",
    "#vocabulary size = 1000\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train('--input=hi_100.txt --model_prefix=m_bpe --vocab_size=1000 --model_type=bpe') \n",
    "sp_bpe = spm.SentencePieceProcessor() \n",
    "sp_bpe.load('m_bpe.model')\n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "# text = \"यह एक मिसाल है! इसमें: कोई विचार नहीं। क्या आप इसे समझ सकते हैं?\"\n",
    "text = remove_punctuation(text)\n",
    "    \n",
    "# print('*** BPE ***') \n",
    "t = sp_bpe.encode_as_pieces(text)\n",
    "\n",
    "ans = []\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='▁'):\n",
    "            continue\n",
    "        temp = temp + x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "# print(t)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c434b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  364356\n",
      "में  :  252654\n",
      "न  :  234294\n",
      "की  :  227524\n",
      "म  :  221198\n",
      "क  :  220756\n",
      "है  :  215573\n",
      "ने  :  209075\n",
      "त  :  200218\n",
      "ल  :  199901\n",
      "प  :  194014\n",
      "स  :  185788\n",
      "र  :  174436\n",
      "व  :  172856\n",
      "से  :  171853\n",
      "ज  :  170867\n",
      "को  :  170855\n",
      "का  :  163981\n",
      "ब  :  163222\n",
      "द  :  158510\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)  \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4550697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  44386\n",
      "हैकि  :  25757\n",
      "केसाथ  :  18660\n",
      "ोंके  :  18036\n",
      "नेके  :  16945\n",
      "कहाकि  :  16149\n",
      "ोंमें  :  16091\n",
      "तेहैं  :  15853\n",
      "केबाद  :  15540\n",
      "ोंको  :  14296\n",
      "ताहै  :  13228\n",
      "नेकहा  :  12397\n",
      "रहाहै  :  12021\n",
      "ोंकी  :  11543\n",
      "हैऔर  :  11321\n",
      "गयाहै  :  11061\n",
      "रहेहैं  :  10181\n",
      "नेकी  :  9805\n",
      "वारको  :  9229\n",
      "करनेके  :  8851\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77163fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee382f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55874a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=hi_100.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: hi_100.txt\n",
      "  input_format: \n",
      "  model_prefix: m_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: hi_100.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5994 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 298383 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 456 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=39649689\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=153\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 298381 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 298381\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 324920\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1364729 min_freq=1990\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220725 size=20 all=7449 active=2256 piece=▁ल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117261 size=40 all=8844 active=3651 piece=िक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74160 size=60 all=10391 active=5198 piece=▁थ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58450 size=80 all=12553 active=7360 piece=त्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43528 size=100 all=14682 active=9489 piece=▁सं\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43241 min_freq=4149\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35408 size=120 all=16900 active=3171 piece=▁किया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28955 size=140 all=18442 active=4713 piece=न्ह\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24411 size=160 all=20405 active=6676 piece=▁राज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21882 size=180 all=22297 active=8568 piece=▁सर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19406 size=200 all=24144 active=10415 piece=▁चु\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19305 min_freq=2919\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17837 size=220 all=26375 active=3387 piece=गर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16215 size=240 all=27984 active=4996 piece=▁जी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14802 size=260 all=29833 active=6845 piece=रो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13436 size=280 all=31773 active=8785 piece=▁उप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12360 size=300 all=32981 active=9993 piece=▁पुलिस\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12356 min_freq=1941\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11890 size=320 all=34340 active=2990 piece=▁इसके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10951 size=340 all=35982 active=4632 piece=चार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10320 size=360 all=37937 active=6587 piece=▁द्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9811 size=380 all=39130 active=7780 piece=▁परि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9445 size=400 all=41055 active=9705 piece=्यों\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9415 min_freq=1429\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8960 size=420 all=42288 active=3222 piece=▁आय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8386 size=440 all=43529 active=4463 piece=▁दौर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8077 size=460 all=45064 active=5998 piece=▁चल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7730 size=480 all=46422 active=7356 piece=▁सकता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7442 size=500 all=47949 active=8883 piece=▁चुनाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7424 min_freq=1125\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7087 size=520 all=49692 active=4134 piece=▁भारतीय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6786 size=540 all=51326 active=5768 piece=▁अव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6635 size=560 all=52202 active=6644 piece=पर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6283 size=580 all=53798 active=8240 piece=▁क्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5999 size=600 all=55396 active=9838 piece=भाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5982 min_freq=904\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5774 size=620 all=56792 active=4071 piece=▁बो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5563 size=640 all=58473 active=5752 piece=योग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5284 size=660 all=59469 active=6748 piece=▁इससे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5123 size=680 all=60536 active=7815 piece=▁कुमार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4968 size=700 all=62054 active=9333 piece=ुक\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4952 min_freq=761\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4780 size=720 all=63542 active=4436 piece=वल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4563 size=740 all=64700 active=5594 piece=▁इस्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4433 size=760 all=65843 active=6737 piece=▁आम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4313 size=780 all=66568 active=7462 piece=▁आने\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4158 size=800 all=67465 active=8359 piece=▁बंद\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4156 min_freq=659\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4025 size=820 all=68540 active=4417 piece=डे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3923 size=840 all=69446 active=5323 piece=▁इसमें\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3812 size=860 all=70222 active=6099 piece=▁मीड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3706 size=880 all=70861 active=6738 piece=▁आयोज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3630 size=900 all=72163 active=8040 piece=▁आया\n",
      "bpe_model_"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** BPE ***\n"
     ]
    }
   ],
   "source": [
    "# BPE\n",
    "#vocabulary size = 2000\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train('--input=hi_100.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe') \n",
    "sp_bpe = spm.SentencePieceProcessor() \n",
    "sp_bpe.load('m_bpe.model')\n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "    \n",
    "# text = \"यह एक मिसाल है! इसमें: कोई विचार नहीं। क्या आप इसे समझ सकते हैं?\"\n",
    "text = remove_punctuation(text)\n",
    "\n",
    "print('*** BPE ***') \n",
    "t = sp_bpe.encode_as_pieces(text)\n",
    "\n",
    "ans = []\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='▁'):\n",
    "            continue\n",
    "        temp = temp + x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "# print(t)\n",
    "# print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c699dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  344111\n",
      "में  :  245378\n",
      "है  :  215573\n",
      "की  :  214581\n",
      "ने  :  178239\n",
      "को  :  164531\n",
      "से  :  161780\n",
      "का  :  147861\n",
      "क  :  131624\n",
      "न  :  123933\n",
      "और  :  115518\n",
      "म  :  112287\n",
      "स  :  110181\n",
      "पर  :  105483\n",
      "प  :  98104\n",
      "व  :  95887\n",
      "ल  :  95702\n",
      "त  :  93873\n",
      "कि  :  92878\n",
      "द  :  90242\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bf4964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  43660\n",
      "हैकि  :  25506\n",
      "केसाथ  :  18473\n",
      "कहाकि  :  16132\n",
      "केबाद  :  14508\n",
      "ोंके  :  13520\n",
      "ोंमें  :  13063\n",
      "नेकहा  :  12048\n",
      "रहाहै  :  12021\n",
      "नेके  :  11827\n",
      "हैऔर  :  11321\n",
      "ताहै  :  11144\n",
      "गयाहै  :  11061\n",
      "रहेहैं  :  10181\n",
      "ोंको  :  10153\n",
      "करनेके  :  8851\n",
      "रहीहै  :  8753\n",
      "ोंकी  :  8386\n",
      "तेहैं  :  8116\n",
      "जाताहै  :  7337\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)  \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1722213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe901b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06a80677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-BERT\n",
    "# max-length = 1000\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "\n",
    "# Insert example text\n",
    "# text = 'मोदी सरकार के पहले कार्यकाल में भी तीन तलाक को लेकर बिल लाया गया था, हालांकि तब यह राज्यसभा में पास नहीं हो पाया था.'\n",
    "\n",
    "# text = \"यह एक मिसाल है! इसमें: कोई विचार नहीं। क्या आप इसे समझ सकते हैं?\"\n",
    "    \n",
    "text = remove_punctuation(text)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',max_len=1000, do_lower_case=False)\n",
    "\n",
    "t = tokenizer.tokenize(text)\n",
    "ans = []\n",
    "\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='#'):\n",
    "            continue\n",
    "        temp = temp + x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "# print(t)\n",
    "# print(ans)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f59094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  346896\n",
      "स  :  329214\n",
      "प  :  309481\n",
      "म  :  304798\n",
      "र  :  299266\n",
      "ब  :  255048\n",
      "में  :  246148\n",
      "न  :  234091\n",
      "है  :  215543\n",
      "की  :  212697\n",
      "ा  :  200585\n",
      "क  :  190235\n",
      "ल  :  186171\n",
      "को  :  173895\n",
      "ने  :  171426\n",
      "ी  :  171424\n",
      "से  :  165456\n",
      "का  :  164329\n",
      "ज  :  149784\n",
      "अ  :  134672\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)  \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05c35556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  44097\n",
      "प्र  :  38369\n",
      "आप  :  26598\n",
      "हैकि  :  25774\n",
      "केसाथ  :  18568\n",
      "मु  :  18101\n",
      "ोंके  :  17051\n",
      "सम  :  16719\n",
      "सु  :  16287\n",
      "कहाकि  :  16155\n",
      "बता  :  15904\n",
      "ोंमें  :  15327\n",
      "सा  :  14917\n",
      "जर  :  14575\n",
      "केबाद  :  14501\n",
      "पुल  :  13838\n",
      "ोंको  :  13730\n",
      "मो  :  13661\n",
      "मौ  :  13167\n",
      "ुलिस  :  12630\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "679d08e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b5c1eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2173bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-BERT\n",
    "# max-length = 2000\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "\n",
    "# Insert example text\n",
    "# text = 'मोदी सरकार के पहले कार्यकाल में भी तीन तलाक को लेकर बिल लाया गया था, हालांकि तब यह राज्यसभा में पास नहीं हो पाया था.'\n",
    "\n",
    "text = remove_punctuation(text)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',max_len=2000, do_lower_case=False)\n",
    "\n",
    "t = tokenizer.tokenize(text)\n",
    "ans = []\n",
    "\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='#'):\n",
    "            continue\n",
    "        temp = temp + x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "# print(t)\n",
    "# print(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8c954c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  346896\n",
      "स  :  329214\n",
      "प  :  309481\n",
      "म  :  304798\n",
      "र  :  299266\n",
      "ब  :  255048\n",
      "में  :  246148\n",
      "न  :  234091\n",
      "है  :  215543\n",
      "की  :  212697\n",
      "ा  :  200585\n",
      "क  :  190235\n",
      "ल  :  186171\n",
      "को  :  173895\n",
      "ने  :  171426\n",
      "ी  :  171424\n",
      "से  :  165456\n",
      "का  :  164329\n",
      "ज  :  149784\n",
      "अ  :  134672\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True) \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d844e92c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  44097\n",
      "प्र  :  38369\n",
      "आप  :  26598\n",
      "हैकि  :  25774\n",
      "केसाथ  :  18568\n",
      "मु  :  18101\n",
      "ोंके  :  17051\n",
      "सम  :  16719\n",
      "सु  :  16287\n",
      "कहाकि  :  16155\n",
      "बता  :  15904\n",
      "ोंमें  :  15327\n",
      "सा  :  14917\n",
      "जर  :  14575\n",
      "केबाद  :  14501\n",
      "पुल  :  13838\n",
      "ोंको  :  13730\n",
      "मो  :  13661\n",
      "मौ  :  13167\n",
      "ुलिस  :  12630\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79ea9f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e2ebdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f96770b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDIC-BERT\n",
    "#max_length = 1000\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', use_fast=False, max_length=1000)\n",
    "model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "\n",
    "# Transform input tokens\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    inp = file.read()\n",
    "\n",
    "# Display the contents of the file\n",
    "# print(text)\n",
    "\n",
    "\n",
    "# text = \"खेल: अर्जुन का कहना है कि बॉडी को फिट रखने के लिए जितना जरूरी एक्सरसाइज है, उतना ही जरूरी है खेल। वह कहते हैं, “जब आप जिम न जा रहे हों, तो खुद को बाकी एक्‍टिविटीज जैसे साइकिलिंग, स्‍विमिंग और वॉकिंग में इन्वॉल्‍व करें। चेंज के लिये खेलना भी अच्‍छा रहता है। गेम का कॉम्पिटीटिव एस्‍पेक्‍ट भी आपकी फिटनेस में हेल्‍प करता है।\"\n",
    "\n",
    "text = remove_punctuation(inp)\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "t = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "ans = []\n",
    "\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='▁'):\n",
    "            continue\n",
    "        temp = temp+x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "\n",
    "# print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "622614b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  328359\n",
      "में  :  241359\n",
      "है  :  214434\n",
      "की  :  198685\n",
      "पर  :  186391\n",
      "को  :  153786\n",
      "से  :  143399\n",
      "ने  :  127586\n",
      "का  :  117574\n",
      "और  :  115469\n",
      "स  :  87775\n",
      "कि  :  86723\n",
      "य  :  80349\n",
      "हैं  :  80268\n",
      "कर  :  72360\n",
      "भी  :  65973\n",
      "ष  :  65022\n",
      "ों  :  57491\n",
      "एक  :  57264\n",
      "क  :  54186\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bbc3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  43495\n",
      "हैकि  :  25212\n",
      "केसाथ  :  18314\n",
      "होंने  :  17726\n",
      "कहाकि  :  16138\n",
      "नेकहा  :  15684\n",
      "कष  :  14439\n",
      "केबाद  :  14413\n",
      "मंतरी  :  12762\n",
      "रहाहै  :  12019\n",
      "हैऔर  :  11352\n",
      "गयाहै  :  11065\n",
      "उनहों  :  10958\n",
      "ोंके  :  10636\n",
      "रहेहैं  :  10171\n",
      "कारय  :  10146\n",
      "राष  :  9688\n",
      "दवारा  :  9373\n",
      "उनहें  :  9144\n",
      "ोंको  :  8914\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True) \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "036326ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce3bb14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "247ea070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDIC-BERT\n",
    "#max_length = 2000\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', use_fast=False, max_length=2000)\n",
    "model = AutoModel.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "\n",
    "# Transform input tokens\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    inp = file.read()\n",
    "\n",
    "# Display the contents of the file\n",
    "# print(text)\n",
    "\n",
    "\n",
    "# text = \"खेल: अर्जुन का कहना है कि बॉडी को फिट रखने के लिए जितना जरूरी एक्सरसाइज है, उतना ही जरूरी है खेल। वह कहते हैं, “जब आप जिम न जा रहे हों, तो खुद को बाकी एक्‍टिविटीज जैसे साइकिलिंग, स्‍विमिंग और वॉकिंग में इन्वॉल्‍व करें। चेंज के लिये खेलना भी अच्‍छा रहता है। गेम का कॉम्पिटीटिव एस्‍पेक्‍ट भी आपकी फिटनेस में हेल्‍प करता है।\"\n",
    "\n",
    "text = remove_punctuation(inp)\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "t = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "ans = []\n",
    "\n",
    "for i in t:\n",
    "    j = i\n",
    "    temp = ''\n",
    "    for x in j:\n",
    "        if(x=='▁'):\n",
    "            continue\n",
    "        temp = temp+x\n",
    "    if(temp!=''):\n",
    "        ans.append(temp)\n",
    "        \n",
    "\n",
    "# print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0453dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  328359\n",
      "में  :  241359\n",
      "है  :  214434\n",
      "की  :  198685\n",
      "पर  :  186391\n",
      "को  :  153786\n",
      "से  :  143399\n",
      "ने  :  127586\n",
      "का  :  117574\n",
      "और  :  115469\n",
      "स  :  87775\n",
      "कि  :  86723\n",
      "य  :  80349\n",
      "हैं  :  80268\n",
      "कर  :  72360\n",
      "भी  :  65973\n",
      "ष  :  65022\n",
      "ों  :  57491\n",
      "एक  :  57264\n",
      "क  :  54186\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2655b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  43495\n",
      "हैकि  :  25212\n",
      "केसाथ  :  18314\n",
      "होंने  :  17726\n",
      "कहाकि  :  16138\n",
      "नेकहा  :  15684\n",
      "कष  :  14439\n",
      "केबाद  :  14413\n",
      "मंतरी  :  12762\n",
      "रहाहै  :  12019\n",
      "हैऔर  :  11352\n",
      "गयाहै  :  11065\n",
      "उनहों  :  10958\n",
      "ोंके  :  10636\n",
      "रहेहैं  :  10171\n",
      "कारय  :  10146\n",
      "राष  :  9688\n",
      "दवारा  :  9373\n",
      "उनहें  :  9144\n",
      "ोंको  :  8914\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True)  \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "729958ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ae62407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2afc215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# White Space Tokenization\n",
    "\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire contents of the file\n",
    "    text = file.read()\n",
    "\n",
    "# text = \"पहले कार्यकाल में भी तीन तलाक को लेकर बिल लाया गया था, हालांकि तब यह राज्यसभा में पास नहीं हो पाया था.\"\n",
    "# Split text by whitespace\n",
    "\n",
    "text = remove_punctuation(text)\n",
    "\n",
    "ans = text.split()\n",
    "# print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "662ce3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "के  :  316939\n",
      "में  :  239605\n",
      "है  :  210204\n",
      "की  :  195240\n",
      "को  :  145757\n",
      "से  :  137934\n",
      "और  :  114839\n",
      "का  :  110395\n",
      "ने  :  102638\n",
      "पर  :  89319\n",
      "हैं  :  79190\n",
      "कि  :  77365\n",
      "भी  :  64487\n",
      "एक  :  49688\n",
      "लिए  :  49179\n",
      "इस  :  47850\n",
      "नहीं  :  47178\n",
      "कर  :  44823\n",
      "ही  :  40538\n",
      "किया  :  36404\n"
     ]
    }
   ],
   "source": [
    "#Unigram frequency of tokens\n",
    "\n",
    "frequency_dict = {}\n",
    "\n",
    "# Count frequency of each string\n",
    "for word in ans:\n",
    "    if word in frequency_dict:\n",
    "        frequency_dict[word] = frequency_dict[word] + 1\n",
    "    else:\n",
    "        frequency_dict[word] = 1\n",
    "\n",
    "sorted_freq = sorted(frequency_dict.items(), key=lambda item: item[1], reverse=True) \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9637000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "केलिए  :  43355\n",
      "हैकि  :  25088\n",
      "केसाथ  :  17422\n",
      "कहाकि  :  16072\n",
      "केबाद  :  14367\n",
      "रहाहै  :  11918\n",
      "नेकहा  :  11665\n",
      "हैऔर  :  11289\n",
      "गयाहै  :  10951\n",
      "रहेहैं  :  10090\n",
      "करनेके  :  8843\n",
      "रहीहै  :  8681\n",
      "जाताहै  :  7229\n",
      "कियागया  :  6858\n",
      "सकताहै  :  6444\n",
      "बतायाकि  :  6443\n",
      "नहींहै  :  6435\n",
      "कियाहै  :  6153\n",
      "होताहै  :  6146\n",
      "करदिया  :  6049\n"
     ]
    }
   ],
   "source": [
    "#Bigram frequency of tokens\n",
    "\n",
    "biT = []\n",
    "\n",
    "for i in range(1,len(ans)):\n",
    "    x = ans[i]\n",
    "    y = ans[i-1]\n",
    "    biT.append(y+x)\n",
    "\n",
    "bi_freq = {}\n",
    "\n",
    "for i in biT:\n",
    "    if i in bi_freq:\n",
    "        bi_freq[i] = bi_freq[i] + 1\n",
    "    else:\n",
    "        bi_freq[i] = 1\n",
    "\n",
    "sorted_freq = sorted(bi_freq.items(), key=lambda item: item[1], reverse=True) \n",
    "        \n",
    "finaluu = sorted_freq[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44d72ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "र्अ  :  1184452\n",
      "अक्  :  976231\n",
      "अर्  :  893634\n",
      "क्अ  :  628404\n",
      "स्अ  :  576768\n",
      "अन्  :  571755\n",
      "अह्  :  557718\n",
      "न्अ  :  521252\n",
      "अम्  :  474427\n",
      "प्अ  :  412102\n",
      "अस्  :  411804\n",
      "क्ए  :  407779\n",
      "आर्  :  404138\n",
      "त्अ  :  360828\n",
      "एअं  :  359507\n",
      "म्अ  :  358569\n",
      "अत्  :  358361\n",
      "ल्अ  :  339855\n",
      "न्ए  :  329014\n",
      "क्आ  :  314203\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of characters\n",
    "\n",
    "token = text.split()\n",
    "\n",
    "result = []\n",
    "\n",
    "for word in token:\n",
    "    result.append(something(word))\n",
    "\n",
    "biT = []\n",
    "fresult = [char for sublist in result for char in sublist]\n",
    "for i in range(1,len(fresult)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(fresult[y]+fresult[x])\n",
    "\n",
    "bi = {}\n",
    "for i in biT:  \n",
    "    if i in bi:\n",
    "        bi[i] = bi[i] + 1\n",
    "    else:\n",
    "        bi[i] = 1\n",
    "sorted_bi = sorted(bi.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "finalb = sorted_bi[:20]\n",
    "\n",
    "for i,j in finalb:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ad4fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर  :  158674\n",
      "और  :  114507\n",
      "पर  :  99668\n",
      "इस  :  82310\n",
      "एक  :  59082\n",
      "लिए  :  54059\n",
      "केलि  :  50058\n",
      "नहीं  :  47048\n",
      "अप  :  44958\n",
      "रने  :  43756\n",
      "तक  :  39804\n",
      "कार  :  39709\n",
      "ताहै  :  36518\n",
      "किया  :  36211\n",
      "नेके  :  35280\n",
      "सके  :  34013\n",
      "कहा  :  32808\n",
      "रका  :  32451\n",
      "नके  :  32304\n",
      "यह  :  31571\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram frequency of syllables\n",
    "ss = syllable(fresult)\n",
    "\n",
    "biT = []\n",
    "for i in range(1,len(ss)-1):\n",
    "    x = i\n",
    "    y = i-1\n",
    "    biT.append(ss[y]+ss[x])\n",
    "\n",
    "uni = {}\n",
    "for i in biT:\n",
    "    if i in uni:\n",
    "        uni[i] = uni[i] + 1\n",
    "    else:\n",
    "        uni[i] = 1\n",
    "\n",
    "sorted_unii = sorted(uni.items(), key=lambda item: item[1], reverse=True)   \n",
    "# print(sorted_uni)\n",
    "\n",
    "finaluu = sorted_unii[:20]\n",
    "\n",
    "for i,j in finaluu:\n",
    "    print(i, \" : \", j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c55d47",
   "metadata": {},
   "source": [
    "# Question : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddca0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"विभाग - विजयपुरा जिला न्यायालय\",\n",
    "    \"खेल: अर्जुन का कहना है कि बॉडी को फिट रखने के लिए जितना जरूरी एक्सरसाइज है, उतना ही जरूरी है खेल। वह कहते हैं, “जब आप जिम न जा रहे हों, तो खुद को बाकी एक्‍टिविटीज जैसे साइकिलिंग, स्‍विमिंग और वॉकिंग में इन्वॉल्‍व करें। चेंज के लिये खेलना भी अच्‍छा रहता है। गेम का कॉम्पिटीटिव एस्‍पेक्‍ट भी आपकी फिटनेस में हेल्‍प करता है।”\",\n",
    "    \"आलिया का कहना है कि वह एक ही एक्सरसाइज से बोर हो जाती हैं।\",\n",
    "    \"पूर्वोत्तर राज्यों में विरोध-प्रदर्शन कर रहे लोग आरएसएस गो-बैक के नारे लगा रहे हैं, साथ ही अपने नारों में सत्ताधारी भाजपा को सतर्क कर रहे हैं. loading. . . सड़कों पर उतरे ऑल असम स्टूडेंट्स यूनियन के कार्यकर्ताओं ने इससे पहले नगरिकता बिल के ख़िलाफ़ मशाल जुलूस निकालकर अपना विरोध जताया.\",\n",
    "    \"फिलहाल यह स्पष्ट नहीं है कि यहां लौटकर आने के बाद उन्हें स्थानीय प्रशासन ने हिरासत में ले लिया या नहीं.\",\n",
    "    \"मोदी सरकार के पहले कार्यकाल में भी तीन तलाक को लेकर बिल लाया गया था, हालांकि तब यह राज्यसभा में पास नहीं हो पाया था.\",\n",
    "    \"इसके बाद लगने की घटना हुई और जिसका धुआं चारो ओर बुरी तरह से फैल गई.\",\n",
    "    \"अब इन पंचायतों के मूल्यांकन के लिए ग्रामीण विकास अभिक रण की ओर निरीक्षण कमेटी का गठन किया जाएगा।\",\n",
    "    \"भारत और रूस के बीच सबसे पहले 2007 में लड़ाकू विमानों की शुरुआती डिजाइन के लिए 295 मिलियन डॉलर का सौदा हुआ था।\",\n",
    "    \"राज्य संपत्ति विभाग, उत्तर प्रदेश द्वारा आरटीआई कार्यकर्ता डा.\",\n",
    "    \"नायर ने अपना शतक 185 गेंदों में 8 चौकों और एक छक्के की मदद से पूरा किया।\",\n",
    "    \"क्या होता है ‘प्राइवेट मेंबर बिल’ जिसे संसद में पेश करने की बात कर रहे हैं बीजेपी सांसद राकेश सिन्हा?\",\n",
    "    \"इंडियन प्रीमियर लीग के चौथे संस्करण की फ्रेंचाइजी टीमों के कप्तान के तौर पर लीग मुकाबले के लिए वानखेड़े स्टेडियम में शुक्रवार को सचिन तेंदुलकर और महेंद्र सिंह धौनी एक दूसरे के आमने-सामने होंगे।\",\n",
    "    \"एनआईए ने सोमवार (सितंबर 16, 2019) को दिल्ली की अदालत में चार्जशीट दायर कर उसमें दावा किया है कि गिरफ्तार आतंकी भारत के अलग-अलग शहरों में आतंकी वारदात को अंजाम देने की फिराक में थे।\",\n",
    "    \"इस आतंकी को दिसंबर 1999 में हुए कंधार विमान अपहरण के बाद यात्रियों की सुरक्षित रिहाई के चलते भारत सरकार को मजबूरन छोड़ना पड़ा था।\",\n",
    "    \": वनडेकीएकपारीमेंसबसेज्यादाचौकेवछक्के।\",\n",
    "    \"संजय किशन और जोगेन मोहन को राजभवन के दरबार हॉल में एक समारोह में राज्यपाल जगदीश मुखी ने पद और गोपनीयता की शपथ दिलाई।\",\n",
    "    \"फिलहाल संभावना है कि परीक्षा नियामक प्राधिकारी कार्यालय की ओर से इस बाबत कोई आदेश जारी किया जाएगा और अभ्यार्थियों को राहत दी जाएगी।\",\n",
    "    \"जी हां हम बात कर रहे हैं इस मैच को देखने आई एक बुजुर्ग महिला फैन की जिन्होंने सबका दिल जीत लिया.\",\n",
    "    \"इसपर क्लिक करने के बाद आपके सामने एक नया पेज खुलेगा। जिसमे आपको निम्नलिखित विवरणों को भरना होगा।\",\n",
    "    \"अब आर-पार की लड़ाई लड़ने का ऐलान करते हुए दूसरे विभागों के कर्मचारी भी समर्थन में आ गए हैं।\",\n",
    "    \"रुद्राक्ष की पहचान के लिए रुद्राक्ष को कुछ देर तक पानी में उबालें यदि रुद्राक्ष का रंग न निकले या उस पर किसी प्रकार का कोई असर न हो, तो वह असली होगा।\",\n",
    "    \"इसके लिए विज्ञापन जारी किया गया है। Loading. . . ये भी पढ़े: सरकारी नौकरी में 2500 पदों पर निकली बम्पर वैकेंसी, तुरंत करें करे आवेदन पदों का विवरण: ऑफिस असिस्टेंट (ग्रेड-3) कुल पदः …\",\n",
    "    \"भारत अभी टी-20 रैंकिंग में पांचवें स्थान पर है और उसे चौथे स्थान पर पहुंचने के लिये वर्तमान सीरीज 5-0 से जीतनी होगी.\",\n",
    "    \"लेकिन आज तक दोनों ही मार्ग में पक्की सड़क नहीं बन पाई। बारिश होने पर यह मार्ग कीचड़ में तब्दील हो जाता है।\"\n",
    "]\n",
    "\n",
    "tokens = [\n",
    "    ['विभाग', 'विजयपुरा जिला न्यायालय'],\n",
    "    ['खेल', 'अर्जुन का', 'कहना है कि' ,'बॉडी को' ,'फिट', 'रखने के लिए', 'जितना जरूरी', 'एक्सरसाइज है', 'उतना ही' ,'जरूरी है','खेल', 'वह', 'कहते हैं', 'जब ','आप', 'जिम' ,'न' ,'जा रहे हों','तो खुद को' ,'बाकी एक्‍टिविटीज' ,'जैसे' ,'साइकिलिंग', 'स्‍विमिंग', 'और', 'वॉकिंग में','इन्वॉल्‍व करें', 'चेंज के लिये', 'खेलना भी' ,'अच्‍छा रहता है', 'गेम का' ,'कॉम्पिटीटिव' ,'एस्‍पेक्‍ट भी' ,'आपकी' ,'फिटनेस में', 'हेल्‍प', 'करता है'],\n",
    "    ['आलिया का', 'कहना है कि', 'वह', 'एक ही', 'एक्सरसाइज से', 'बोर', 'हो जाती हैं'],\n",
    "    ['पूर्वोत्तर', 'राज्यों में', 'विरोध-प्रदर्शन', 'कर रहे', 'लोग', 'आरएसएस गो-बैक के', 'नारे', 'लगा रहे हैं', 'साथ ही', 'अपने', 'नारों में', 'सत्ताधारी', 'भाजपा को', 'सतर्क', 'कर रहे हैं', 'loading', 'सड़कों पर', 'उतरे', 'ऑल असम स्टूडेंट्स यूनियन के', 'कार्यकर्ताओं ने', 'इससे पहले', 'नगरिकता बिल के', 'ख़िलाफ़', 'मशाल जुलूस', 'निकालकर', 'अपना', 'विरोध', 'जताया'],\n",
    "    ['फिलहाल', 'यह', 'स्पष्ट', 'नहीं है कि', 'यहां', 'लौटकर', 'आने के', 'बाद', 'उन्हें', 'स्थानीय', 'प्रशासन ने', 'हिरासत में', 'ले लिया', 'या', 'नहीं'],\n",
    "    ['मोदी सरकार के', 'पहले', 'कार्यकाल में भी', 'तीन तलाक को लेकर', 'बिल', 'लाया गया था', 'हालांकि', 'तब', 'यह', 'राज्यसभा में', 'पास', 'नहीं', 'हो पाया था'],\n",
    "    ['इसके बाद', 'लगने की', 'घटना हुई', 'और', 'जिसका', 'धुआं', 'चारो ओर', 'बुरी', 'तरह से', 'फैल गई'],\n",
    "    ['अब', 'इन पंचायतों के', 'मूल्यांकन के लिए', 'ग्रामीण विकास अभिक रण की', 'ओर', 'निरीक्षण', 'कमेटी का', 'गठन', 'किया जाएगा'],\n",
    "    ['भारत', 'और', 'रूस के बीच', 'सबसे पहले', '2007 में', 'लड़ाकू', 'विमानों की', 'शुरुआती', 'डिजाइन के लिए', '295 मिलियन डॉलर का', 'सौदा हुआ था'],\n",
    "    ['राज्य संपत्ति विभाग', 'उत्तर प्रदेश', 'द्वारा', 'आरटीआई कार्यकर्ता डा'],\n",
    "    ['नायर ने', 'अपना', 'शतक', '185 गेंदों में', '8 चौकों', 'और', 'एक छक्के की', 'मदद से', 'पूरा किया'],\n",
    "    ['क्या', 'होता है', '‘प्राइवेट मेंबर बिल’', 'जिसे संसद में', 'पेश करने की', 'बात', 'कर रहे हैं', 'बीजेपी सांसद राकेश सिन्हा'],\n",
    "    ['इंडियन प्रीमियर लीग के', 'चौथे', 'संस्करण की', 'फ्रेंचाइजी', 'टीमों के', 'कप्तान के', 'तौर पर', 'लीग', 'मुकाबले के लिए', 'वानखेड़े स्टेडियम में', 'शुक्रवार को', 'सचिन तेंदुलकर', 'और', 'महेंद्र सिंह धौनी', 'एक दूसरे के', 'आमने-सामने होंगे'],\n",
    "    ['एनआईए ने', 'सोमवार सितंबर 16 2019 को', 'दिल्ली की', 'अदालत में', 'चार्जशीट', 'दायर कर', 'उसमें', 'दावा किया है कि', 'गिरफ्तार', 'आतंकी', 'भारत के', 'अलग-अलग', 'शहरों में', 'आतंकी', 'वारदात को', 'अंजाम', 'देने की', 'फिराक में थे'],\n",
    "    ['इस आतंकी को', 'दिसंबर 1999 में हुए', 'कंधार विमान अपहरण के बाद', 'यात्रियों की', 'सुरक्षित', 'रिहाई के चलते', 'भारत सरकार को', 'मजबूरन', 'छोड़ना पड़ा था'],\n",
    "    ['वनडेकीएकपारीमेंसबसेज्यादाचौकेवछक्के'],\n",
    "    ['संजय किशन', 'और', 'जोगेन मोहन को', 'राजभवन के', 'दरबार हॉल में', 'एक समारोह में', 'राज्यपाल जगदीश मुखी ने', 'पद', 'और', 'गोपनीयता की', 'शपथ दिलाई'],\n",
    "    ['फिलहाल', 'संभावना है कि', 'परीक्षा नियामक प्राधिकारी कार्यालय की', 'ओर से', 'इस बाबत', 'कोई आदेश', 'जारी', 'किया जाएगा', 'और', 'अभ्यार्थियों को', 'राहत', 'दी जाएगी'],\n",
    "    ['जी हां', 'हम', 'बात', 'कर रहे हैं', 'इस मैच को', 'देखने आई', 'एक', 'बुजुर्ग महिला', 'फैन की', 'जिन्होंने', 'सबका', 'दिल', 'जीत लिया'],\n",
    "    ['इसपर', 'क्लिक करने के बाद', 'आपके', 'सामने', 'एक', 'नया', 'पेज', 'खुलेगा', 'जिसमे आपको', 'निम्नलिखित', 'विवरणों को', 'भरना होगा'],\n",
    "    ['अब', 'आर-पार की', 'लड़ाई', 'लड़ने का', 'ऐलान', 'करते हुए', 'दूसरे', 'विभागों के', 'कर्मचारी भी', 'समर्थन में', 'आ गए हैं'],\n",
    "    ['रुद्राक्ष की', 'पहचान के लिए', 'रुद्राक्ष को', 'कुछ', 'देर तक', 'पानी में', 'उबालें', 'यदि', 'रुद्राक्ष का', 'रंग', 'न', 'निकले', 'या', 'उस पर', 'किसी प्रकार का', 'कोई असर', 'न हो', 'तो वह', 'असली होगा'],\n",
    "    ['इसके लिए', 'विज्ञापन', 'जारी किया गया है', 'ये भी', 'पढ़े', 'सरकारी', 'नौकरी में', '2500 पदों पर', 'निकली बम्पर', 'वैकेंसी', 'तुरंत करें करे', 'आवेदन', 'पदों का', 'विवरण', 'ऑफिस असिस्टेंट (ग्रेड-3)', 'कुल', 'पदः'],\n",
    "    ['भारत', 'अभी', 'टी-20', 'रैंकिंग में', 'पांचवें स्थान पर है', 'और', 'उसे चौथे स्थान पर', 'पहुंचने के लिये', 'वर्तमान', 'सीरीज 5-0 से', 'जीतनी होगी'],\n",
    "    ['लेकिन', 'आज तक', 'दोनों ही', 'मार्ग में', 'पक्की सड़क', 'नहीं', 'बन पाई', 'बारिश', 'होने पर', 'यह मार्ग', 'कीचड़ में', 'तब्दील', 'हो जाता है']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc43b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tp(model_token,my_token):\n",
    "    cnt = 0\n",
    "    for i in model_token:\n",
    "        if i in my_token:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def find_fp(model_token,my_token):\n",
    "    cnt = 0\n",
    "    for i in model_token:\n",
    "        if i not in my_token:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def find_fn(model_token,my_token):\n",
    "    cnt = 0\n",
    "    for i in my_token:\n",
    "        if i not in model_token:\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3134776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  8.282828282828284 %\n",
      "recall :  25.624999999999996 %\n",
      "F1 Score :  12.519083969465653 %\n"
     ]
    }
   ],
   "source": [
    "# Using Unigram\n",
    "\n",
    "tp = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "\n",
    "for ii in range(0,25):\n",
    "    text = sentences[ii]\n",
    "    text = remove_punctuation(text)\n",
    "    t = sp_unigram.encode_as_pieces(text) \n",
    "    ans = []\n",
    "    for i in t:\n",
    "        j = i\n",
    "        temp = ''\n",
    "        for x in j:\n",
    "            if(x=='▁' or x=='#'):\n",
    "                continue\n",
    "            temp = temp + x\n",
    "        if(temp!=''):\n",
    "            ans.append(temp)\n",
    "            \n",
    "    tp += find_tp(ans,tokens[ii])\n",
    "    fp += find_fp(ans,tokens[ii])\n",
    "    fn += find_fn(ans,tokens[ii]) \n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "print(\"precision : \",precision*100,\"%\")\n",
    "print(\"recall : \",recall*100,\"%\")\n",
    "print(\"F1 Score : \",fscore*100,\"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbe69e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  6.796116504854369 %\n",
      "recall :  21.9435736677116 %\n",
      "F1 Score :  10.378057820607857 %\n"
     ]
    }
   ],
   "source": [
    "# BPE\n",
    "#vocabulary size = 1000\n",
    "\n",
    "tp = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "\n",
    "for ii in range(0,25):\n",
    "    text = sentences[ii]\n",
    "    text = remove_punctuation(text) \n",
    "    t = sp_bpe.encode_as_pieces(text)\n",
    "    ans = []\n",
    "    for i in t:\n",
    "        j = i\n",
    "        temp = ''\n",
    "        for x in j:\n",
    "            if(x=='▁' or x=='#'):\n",
    "                continue\n",
    "            temp = temp + x\n",
    "        if(temp!=''):\n",
    "            ans.append(temp)\n",
    "            \n",
    "    tp += find_tp(ans,tokens[ii])\n",
    "    fp += find_fp(ans,tokens[ii])\n",
    "    fn += find_fn(ans,tokens[ii]) \n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "print(\"precision : \",precision*100,\"%\")\n",
    "print(\"recall : \",recall*100,\"%\")\n",
    "print(\"F1 Score : \",fscore*100,\"%\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a3fd566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  12.743823146944083 %\n",
      "recall :  30.721003134796238 %\n",
      "F1 Score :  18.014705882352942 %\n"
     ]
    }
   ],
   "source": [
    "# M-BERT\n",
    "# max-length = 1000\n",
    "\n",
    "tp = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "\n",
    "for ii in range(0,25):\n",
    "    text = sentences[ii]\n",
    "    text = remove_punctuation(text)\n",
    "    t = tokenizer.tokenize(text)\n",
    "    ans = []\n",
    "    for i in t:\n",
    "        j = i\n",
    "        temp = ''\n",
    "        for x in j:\n",
    "            if(x=='▁' or x=='#'):\n",
    "                continue\n",
    "            temp = temp + x\n",
    "        if(temp!=''):\n",
    "            ans.append(temp)\n",
    "            \n",
    "    tp += find_tp(ans,tokens[ii])\n",
    "    fp += find_fp(ans,tokens[ii])\n",
    "    fn += find_fn(ans,tokens[ii]) \n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "print(\"precision : \",precision*100,\"%\")\n",
    "print(\"recall : \",recall*100,\"%\")\n",
    "print(\"F1 Score : \",fscore*100,\"%\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82f31d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  11.965811965811966 %\n",
      "recall :  30.721003134796238 %\n",
      "F1 Score :  17.223198594024602 %\n"
     ]
    }
   ],
   "source": [
    "# Indic-BERT\n",
    "tp = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "\n",
    "for ii in range(0,25):\n",
    "    text = sentences[ii]\n",
    "    text = remove_punctuation(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    t = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    ans = []\n",
    "    for i in t:\n",
    "        j = i\n",
    "        temp = ''\n",
    "        for x in j:\n",
    "            if(x=='▁' or x=='#'):\n",
    "                continue\n",
    "            temp = temp + x\n",
    "        if(temp!=''):\n",
    "            ans.append(temp)\n",
    "\n",
    "    tp += find_tp(ans,tokens[ii])\n",
    "    fp += find_fp(ans,tokens[ii])\n",
    "    fn += find_fn(ans,tokens[ii])\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "print(\"precision : \",precision*100,\"%\")\n",
    "print(\"recall : \",recall*100,\"%\")\n",
    "print(\"F1 Score : \",fscore*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f05612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  21.176470588235293 %\n",
      "recall :  39.74763406940063 %\n",
      "F1 Score :  27.631578947368418 %\n"
     ]
    }
   ],
   "source": [
    "# Whitespace\n",
    "\n",
    "tp = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "\n",
    "for ii in range(0,25):\n",
    "    text = sentences[ii]\n",
    "    text = remove_punctuation(text)\n",
    "    t = text.split()\n",
    "    ans = []\n",
    "    for i in t:\n",
    "        j = i\n",
    "        temp = ''\n",
    "        for x in j:\n",
    "            if(x=='▁' or x=='#'):\n",
    "                continue\n",
    "            temp = temp + x\n",
    "        if(temp!=''):\n",
    "            ans.append(temp)\n",
    "\n",
    "    tp += find_tp(ans,tokens[ii])\n",
    "    fp += find_fp(ans,tokens[ii])\n",
    "    fn += find_fn(ans,tokens[ii])\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = (2*precision*recall)/(precision+recall)\n",
    "print(\"precision : \",precision*100,\"%\")\n",
    "print(\"recall : \",recall*100,\"%\")\n",
    "print(\"F1 Score : \",fscore*100,\"%\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
